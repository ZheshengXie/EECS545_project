import argparse
import json
from pathlib import Path
from types import SimpleNamespace

import numpy as np
import torch

from utils import import_class, load_model, save_model, save_model_from_checkpoint, pack_sample_files, transform_back


def load_config():
    # load config from json
    config_path = Path("config") / opt.config
    print("Config:", str(config_path))
    with config_path.open("r") as fin:
        config = json.loads(fin.read())
    #with open("gan_mnist.json", "w") as fout:
        #fout.write(json.dumps(config, indent=4))
    return SimpleNamespace(**config)


def eval_model(training_config, G, device):
    import matplotlib.pyplot as plt
    results_dir = Path("4_results") / training_config["exp_dir"]
    results_dir.mkdir(parents=True, exist_ok=True)
    G.to(device)
    G.eval()  # set training attribute as False

    # random sample
    for j in range(1):
        sample_num = 16
        z = torch.randn((sample_num, *G.get_input_shape()), device=device)
        output = G(z).detach().cpu().numpy()
        output = transform_back(training_config["dataset"], output)
        for i in range(sample_num):  # show the first 16 images
            plt.subplot(4, 4, i + 1)
            plt.imshow(output[i])
            plt.axis('off')
        plt.savefig(str(results_dir / "sample_{}.png".format(j)))
    plt.show()

    # gradually changing
    sample_num = 4
    changing_num = 8
    for i in range(sample_num):
        z = torch.randn((changing_num, *G.get_input_shape()), device=device)
        d = (z[changing_num - 1, :] - z[0, :]) / (changing_num - 1)
        for j in range(1, changing_num - 1):
            z[j] = z[j - 1] + d
        output = G(z).detach().cpu().numpy()
        output = transform_back(training_config["dataset"], output)
        for j in range(changing_num):
            plt.subplot(sample_num, changing_num, i * changing_num + j + 1)
            plt.imshow(output[j])
            plt.axis('off')
    plt.savefig(str(results_dir / "changing.png"))
    plt.show()


def show_sample(training_config, epoch):
    import matplotlib.pyplot as plt
    results_dir = Path("4_results") / training_config["exp_dir"]
    different_epoch_dir = results_dir / "diff_epoch"
    different_epoch_dir.mkdir(exist_ok=True, parents=True)
    # load samples
    sample_path = Path("2_experiments") / training_config["exp_dir"] / "sample_{:0>4d}.npy".format(epoch)
    output = np.load(str(sample_path))
    # transform back
    output = transform_back(training_config["dataset"], output)
    # display
    print("#samples: {}    Image size: {}".format(output.shape[0], output.shape[1:]))
    for i in range(16):  # show the first 16 images
        plt.subplot(4, 4, i + 1)
        plt.imshow(output[i])
        plt.axis('off')
    plt.savefig(str(different_epoch_dir / "{:0>4d}.png".format(epoch)))
    plt.show()


def plot_loss(training_config):
    import matplotlib.pyplot as plt
    stat = torch.load(Path("2_experiments") / training_config["exp_dir"] / "stat.pth")
    results_dir = Path("4_results") / training_config["exp_dir"]
    results_dir.mkdir(parents=True, exist_ok=True)

    loss_G = stat["training_loss_G"]
    loss_D = stat["training_loss_D"]
    end_epoch = len(loss_G) if opt.epoch == 0 else min(len(loss_G), opt.epoch)

    plt.plot(range(end_epoch), loss_G[:end_epoch])
    plt.xlabel("#epoch")
    plt.ylabel("loss")
    plt.title("Loss of Generator")
    plt.savefig(str(results_dir / "loss_G.png"))
    plt.show()

    plt.plot(range(end_epoch), loss_D[:end_epoch])
    plt.xlabel("#epoch")
    plt.ylabel("loss")
    plt.title("Loss of Discriminator")
    plt.savefig(str(results_dir / "loss_D.png"))
    plt.show()


def main(mode):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("Device: {}".format(device))
    config = load_config()
    model_path = Path("3_models") / config.general["model_path"]
    Trainer = import_class(config.general["trainer"])
    Generator = import_class(config.general["generator"])
    Discriminator = import_class(config.general["discriminator"])

    G = Generator(config.model)
    D = Discriminator(config.model)
    if mode == "train":
        trainer = Trainer(config.training, G, D, device)
        trainer.train()
        save_model(G, D, model_path)
    elif mode == "eval":
        load_model(G, D, model_path)
        eval_model(config.training, G, device)
    elif mode == "show_sample":  # show samples generated by G in the given epoch
        print("Show samples in epoch {}".format(opt.epoch))
        show_sample(config.training, epoch=opt.epoch)
    elif mode == "draw_loss":
        plot_loss(config.training)
    elif mode == "save_model":  # save model from checkpoint
        checkpoint_path = Path("2_experiments") / config.training["exp_dir"] / "ckp_{:0>4d}.pth".format(opt.epoch)
        print("Save model from {}".format(checkpoint_path))
        save_model_from_checkpoint(G, D, checkpoint_path, model_path)
    elif mode == "pack":  # pack all the sample files to a zip file
        pack_sample_files(Path("2_experiments") / config.training["exp_dir"])
    else:
        print("Unknown Mode")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--mode", type=str, default="eval",
                        help="train, eval, show_sample, draw_loss, save_model, pack")
    parser.add_argument("--config", type=str, default="dcgan_wgan_faces_100.json", help="config file path")
    parser.add_argument("--epoch", type=int, default=5000, help="the given epoch")
    opt = parser.parse_args()

    print("Mode: ", opt.mode)
    main(opt.mode)
